{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05bc3cb5-7a64-4ff6-8fa9-f14bf335db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcad80b7-5799-4243-9584-dd2d8061617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# flatten and  normalize pixel in to [0-1]\n",
    "X_train = X_train.reshape(len(X_train), 28 * 28) / 255.0\n",
    "X_test = X_test.reshape(len(X_test), 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d07e36-ffae-4b75-8c01-ccaca7a41601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pixels per image\n",
    "num_features = 784 \n",
    "num_classes = 10  # Digits 0-9\n",
    "learning_rate = 0.00019\n",
    "theta = 550 # Threshold for activation\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = np.eye(num_classes)[y_train]\n",
    "y_test_encoded = np.eye(num_classes)[y_test]\n",
    "\n",
    "# Initialize weights and bias with 0\n",
    "weights = np.zeros((num_features, num_classes))\n",
    "bias = np.zeros(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85452bd9-df31-4407-ada3-a2604abbcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is activation function of perceptron learning\n",
    "def activation_function(y_in, theta):\n",
    "    result = np.zeros_like(y_in)\n",
    "    result[y_in > theta] = 1\n",
    "    result[(y_in <= theta) & (y_in >= -theta)] = 0\n",
    "    result[y_in < -theta] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9323d575-3afd-4529-b6bb-4d082e335b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More epochs give the model additional time to fine-tune the weights.\n",
    "# epochs = 200\n",
    "epochs = 15\n",
    "# Training function\n",
    "def train_model(X_train, y_train_encoded, weights, bias, learning_rate, epochs, theta):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(X_train)):\n",
    "            # This is the Net\n",
    "            y_in = np.dot(X_train[i], weights) + bias\n",
    "            # this is the output\n",
    "            y_pred = activation_function(y_in, theta)\n",
    "\n",
    "            # Update weights and bias for each class\n",
    "            for j in range(num_classes):\n",
    "            # y_train_encoded[i][j] this is the target\n",
    "                if y_pred[j] != y_train_encoded[i][j]:\n",
    "                    weights[:, j] += learning_rate * y_train_encoded[i][j] * X_train[i]\n",
    "                    bias[j] += learning_rate * y_train_encoded[i][j]\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} completed\")\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9e40fb-032b-48ce-aab9-986db33086c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X_test, y_test_encoded, weights, bias, theta):\n",
    "  \n",
    "    y_test_pred_scores = np.dot(X_test, weights) + bias\n",
    "    y_test_pred = np.argmax(y_test_pred_scores, axis=1)\n",
    "    y_test_actual = np.argmax(y_test_encoded, axis=1)\n",
    "    correct_predictions = np.sum(y_test_actual == y_test_pred)\n",
    "    total_predictions = len(y_test_actual)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "    return test_accuracy, y_test_pred, y_test_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa179ee-5d2a-45f8-916b-7029ef28e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 completed\n",
      "Epoch 2/15 completed\n",
      "Epoch 3/15 completed\n",
      "Epoch 4/15 completed\n",
      "Epoch 5/15 completed\n",
      "Epoch 6/15 completed\n",
      "Epoch 7/15 completed\n",
      "Epoch 8/15 completed\n",
      "Epoch 9/15 completed\n",
      "Epoch 10/15 completed\n",
      "Epoch 11/15 completed\n",
      "Epoch 12/15 completed\n",
      "Epoch 13/15 completed\n",
      "Epoch 14/15 completed\n",
      "Epoch 15/15 completed\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "weights, bias = train_model(X_train, y_train_encoded, weights, bias, learning_rate, epochs, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ebc465b-5455-472f-a6fd-1b4c1a0e4771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.38%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_accuracy, y_test_pred, y_test_actual = test_model(X_test, y_test_encoded, weights, bias, theta)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd00cb62-654d-472d-ad8f-c9490444e2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plot some test images with true and predicted labels....i got this plotting implementation form chatGPT\n",
    "num_images = 1  # Number of images to display\n",
    "indices = np.random.choice(len(X_test), num_images, replace=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, idx in enumerate(indices):\n",
    "    image = X_test[idx].reshape(28, 28)  # Reshape to 28x28 image\n",
    "    true_label = y_test_actual[idx]  # Get true label\n",
    "    predicted_label = y_test_pred[idx]  # Get predicted label\n",
    "\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Pred: {predicted_label} \\n True: {true_label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d12141-8dc8-4db6-afcf-bf71296a48da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
